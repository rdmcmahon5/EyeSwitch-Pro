{
  "name": "Eyeswitch-pro",
  "tagline": "",
  "body": "### What is EyeSwitch?\r\nEyeSwitch Pro is a new mechanism for interacting with home electronics. EyeSwitch is a system that allows users to toggle power in real time using any camera enabled device. This project aims to create an ecosystem that makes the use of home electronics more accessible to those with physical and mobile impairments. In the United States, there are 35.2 million individuals that have difficulty with physical activity, 250,000 with spinal cord injuries, and 30,000 with ALS. All of these individuals could potentially benefit from EyeSwitch by having a new, non-physically demanding, way of interacting with the home. The full EyeSwitch ecosystem was implemented including hardware switches, a registration server, a correlation server, and an EyeSwitch compatible device. For this project, an Android app is used as an example of an EyeSwitch device. The eventual motivation is to move the client application to the Pupil Pro eye tracker to increase the size of the potential benefactors. The Pupil Pro tracks a user's pupil and projects the pupil focal point onto a 2D image of the surroundings. \r\n\r\n### Overview\r\nThe EyeSwitch ecosystem allows a user to toggle power to household electronics by simply looking at the electronic with a Pupil Pro while blinking, or by capturing a photo of the electronic with a compatible EyeSwitch device. The electronic needs to be connected to an EyeSwitch hardware unit. The user takes an initial photo of the electronic along with its configuration identifier and then subsequent photos of electronic toggle power.\r\n\r\n### EyeSwitch Pro \r\nEyeSwitch Pro takes advantage of an enhanced feature set and improed object matching to increase the accuracy over the base EyeSwitch system backend.  \r\n\r\n### Timeline\r\n1. Salvage as much as possible from the original EyeSwitch system\r\n2. Rebuild and refine the design of the EyeSwitch hardware switches\r\n3. Allow the backend server to be extensible with the new backend upgrades\r\n4. Modify the Android Application to capture more data\r\n\r\nMidterm Review: Working demo of a beta version EyeSwitch Pro\r\n\r\n5. Research different potential object matching techniques.\r\n6. Implement creating stereo depth maps from the video frames. \r\n7. Evaluate the performance of all the different object matching techniques.  \r\n8. Combine RANSAC and NN to merge the accuracy results.\r\n9. Reduce network to provide a better overall latency.\r\n10. Tune all of the parameters to provide the best tradeoff of runtime and accuracy. \r\n \r\n\r\nFinal Paper:\r\n<https://homes.cs.washington.edu/~mjj47/EyeSwitch_Pro.pdf>\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}